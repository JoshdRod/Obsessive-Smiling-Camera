import cv2
import numpy as np
import math

# Load face + smile classifier
faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
smileCascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_smile.xml")

# Initialise the camera
cam = cv2.VideoCapture(0)
cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)

smiles = [] # Smile data stored in here 

while True:
    # Take in image
    ret, frame = cam.read()
    frame = cv2.flip(frame, 1)# flip fram over (1 is flip on y axis)
    # Detect faces
    greyscaleImage = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Greyscale makes image processing easier (makes sense as haar features)
    faces = faceCascade.detectMultiScale(greyscaleImage, scaleFactor=1.1, minNeighbors=12, minSize=(30,30))
    
    # Draw rectangle around face
    for (x, y, w, h) in faces:
        cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 2)

        ## Smile detection
        # Get region of interest (ROI) of smile
        faceImage = greyscaleImage[y:y+h, x:x+w]
        smilesInImage = smileCascade.detectMultiScale(faceImage, scaleFactor=1.8, minNeighbors=35, minSize=(25,25))

        # For each smile detected
        for (sx, sy, sw, sh) in smilesInImage:
            # Draw a rectangle around it
            cv2.rectangle(frame, (x + sx, y + sy), (x + sx + sw, y + sy + sh), (0, 255, 0), 2)
            widthRatio = sx / x
            heightRatio = sy / y
            smileIntensity = 1 - math.exp(-(10 * widthRatio))

    # Show frame with faces
    cv2.imshow("Detected Faces", frame)

    if cv2.waitKey(1) == 27: # 27 = esc
        break

cam.release()
cv2.destroyAllWindows()